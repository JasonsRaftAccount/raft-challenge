# LLM Provider: "openrouter" or "ollama"
PROVIDER=openrouter

# OpenRouter Configuration
OPENROUTER_API_KEY=your_key_here
OPENROUTER_MODEL=openai/gpt-oss-120b:exacto
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Ollama Configuration (for local testing)
# PROVIDER=ollama
# OLLAMA_MODEL=gpt-oss:20b
# OLLAMA_BASE_URL=http://localhost:11434/v1

# LLM Parameters
LLM_TEMPERATURE=0
MAX_TOKENS=8192

# Batch Processing
CHUNK_SIZE=20
PARSE_CONCURRENCY=10
VALIDATE_CONCURRENCY=10
MAX_RETRIES=3
RETRY_BASE_DELAY=1.0

# API Configuration
DUMMY_API_URL=http://localhost:5001
